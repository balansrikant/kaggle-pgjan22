{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "Submission File\n",
    "For each id in the test set, you must predict a probability for the target variable. The file should contain a header and have the following format:\n",
    "\n",
    "https://www.kaggle.com/c/tabular-playground-series-nov-2021/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : kaggle-pgdec21\n",
      "    active env location : C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgdec21\n",
      "            shell level : 1\n",
      "       user config file : C:\\Users\\globetrekker\\.condarc\n",
      " populated config files : C:\\Users\\globetrekker\\.condarc\n",
      "          conda version : 4.10.3\n",
      "    conda-build version : 3.21.4\n",
      "         python version : 3.8.8.final.0\n",
      "       virtual packages : __win=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : C:\\ProgramData\\Anaconda3  (writable)\n",
      "      conda av data dir : C:\\ProgramData\\Anaconda3\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\ProgramData\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\globetrekker\\.conda\\pkgs\n",
      "                          C:\\Users\\globetrekker\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\ProgramData\\Anaconda3\\envs\n",
      "                          C:\\Users\\globetrekker\\.conda\\envs\n",
      "                          C:\\Users\\globetrekker\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.10.3 requests/2.25.1 CPython/3.8.8 Windows/10 Windows/10.0.19041\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c04be2df-43b3-4c66-ae0e-c17ff6bf7a45",
    "_uuid": "e1abf160-08a9-4188-a996-16dcee5395ec",
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:01.273778Z",
     "iopub.status.busy": "2021-11-12T19:01:01.272805Z",
     "iopub.status.idle": "2021-11-12T19:01:01.309507Z",
     "shell.execute_reply": "2021-11-12T19:01:01.308884Z",
     "shell.execute_reply.started": "2021-11-12T19:01:01.273661Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:01.311465Z",
     "iopub.status.busy": "2021-11-12T19:01:01.311078Z",
     "iopub.status.idle": "2021-11-12T19:01:03.981131Z",
     "shell.execute_reply": "2021-11-12T19:01:03.980277Z",
     "shell.execute_reply.started": "2021-11-12T19:01:01.311436Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, gc, copy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:01.311465Z",
     "iopub.status.busy": "2021-11-12T19:01:01.311078Z",
     "iopub.status.idle": "2021-11-12T19:01:03.981131Z",
     "shell.execute_reply": "2021-11-12T19:01:03.980277Z",
     "shell.execute_reply.started": "2021-11-12T19:01:01.311436Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import utility as ut\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "%config Completer.use_jedi = False\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(path):\n",
    "    df_train = pd.read_csv(path + 'train.csv')\n",
    "    df_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "    # drop this because only 1 row\n",
    "    df_train.drop(list(df_train[df_train['Cover_Type']==5].index), axis=0, inplace=True)\n",
    "\n",
    "    # drop these because only 1 value\n",
    "    print('Singular columns')\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].nunique() == 1:\n",
    "            print(col)\n",
    "            df_train.drop(col, axis=1, inplace=True)\n",
    "            df_test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    # drop these because no additional info\n",
    "    ids = df_test['Id']\n",
    "    df_train.drop(['Id'], axis=1, inplace=True)\n",
    "    df_test.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    memory_usage = df_train.memory_usage(deep=True) / 1024 ** 2\n",
    "    print('start mem %.2f MB' % (memory_usage.sum()))\n",
    "\n",
    "    for col in df_train.columns:\n",
    "        if 'Soil_Type' in col:\n",
    "            df_train[col] = df_train[col].astype('category')\n",
    "            df_test[col] = df_test[col].astype('category')\n",
    "            continue\n",
    "        if 'Wilderness' in col:\n",
    "            df_train[col] = df_train[col].astype('category')\n",
    "            df_test[col] = df_test[col].astype('category')\n",
    "            continue\n",
    "        if 'Cover_Type' in col:\n",
    "            df_train[col] = df_train[col].astype('uint8')\n",
    "            continue\n",
    "\n",
    "        if df_train[col].min() >= 0 and df_train[col].max() <= 255:\n",
    "            df_train[col] = df_train[col].astype('uint8')\n",
    "            df_test[col] = df_test[col].astype('uint8')\n",
    "        elif df_train[col].min() >= 0 and df_train[col].max() <= 65535:\n",
    "            df_train[col] = df_train[col].astype('uint16')\n",
    "            df_test[col] = df_test[col].astype('uint16')\n",
    "        elif df_train[col].min() >= -128 and df_train[col].max() <= 127:\n",
    "            df_train[col] = df_train[col].astype('int8')\n",
    "            df_test[col] = df_test[col].astype('int8')\n",
    "        elif df_train[col].min() >= -32768 and df_train[col].max() <= 32767:\n",
    "            df_train[col] = df_train[col].astype('int16')\n",
    "            df_test[col] = df_test[col].astype('int16')\n",
    "\n",
    "    memory_usage = df_train.memory_usage(deep=True) / 1024 ** 2\n",
    "    print('end mem %.2f MB' % (memory_usage.sum()))\n",
    "    \n",
    "    return df_train, df_test, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_df(df_train, df_test, target):\n",
    "    \n",
    "    df_train_in = copy.deepcopy(df_train)\n",
    "    df_test_in = copy.deepcopy(df_test)\n",
    "    \n",
    "    df_target = df_train_in[target]\n",
    "    df_train_in.drop(target, axis=1, inplace=True)\n",
    "    \n",
    "    cols_train = df_train_in.columns\n",
    "    cols_test = df_test_in.columns\n",
    "    \n",
    "    scale_features = []\n",
    "    for col in df_train_in.columns:\n",
    "        if df_train_in[col].dtypes == 'category':\n",
    "            continue\n",
    "        else:\n",
    "            scale_features.append(col)\n",
    "    \n",
    "    # define transformer\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[('scale', StandardScaler(), scale_features)], \n",
    "        remainder='passthrough')\n",
    "    \n",
    "    # transform training data\n",
    "    df_train_in = pd.DataFrame(transformer.fit_transform(df_train_in))\n",
    "    df_train_in.columns = cols_train\n",
    "    df_train_in[target] = df_target\n",
    "    df_train_in.loc[df_train_in[target].isnull(), target] = 1\n",
    "    df_train_in[target] = df_train_in[target].astype('uint8')\n",
    "    \n",
    "    # transform test data\n",
    "    df_test_in = pd.DataFrame(transformer.transform(df_test_in))\n",
    "    df_test_in.columns = cols_test\n",
    "    \n",
    "    # reset data types\n",
    "    for col in df_train_in.columns:\n",
    "        if df_train[col].dtypes == 'category':\n",
    "            df_train_in[col] = df_train_in[col].astype('category') \n",
    "        if col in scale_features:\n",
    "            df_train_in[col] = df_train_in[col].astype('float32') \n",
    "              \n",
    "    return df_train_in, df_test_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular columns\n",
      "Soil_Type7\n",
      "Soil_Type15\n",
      "start mem 1647.95 MB\n",
      "end mem 267.03 MB\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "df_train, df_test, ids = get_datasets('../input/tabular-playground-series-dec-2021/')\n",
    "df_train_sc, df_test_sc = get_scaled_df(df_train, df_test, 'Cover_Type')\n",
    "\n",
    "# get models\n",
    "models = ut.get_models()\n",
    "\n",
    "# split data\n",
    "X_train, X_val, y_train, y_val, original_features = ut.split_dataset(df_train, df_test, 'Cover_Type')\n",
    "X_train_sc, X_val_sc, y_train_sc, y_val_sc, original_features = ut.split_dataset(df_train_sc, df_test_sc, 'Cover_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get baseline score - rf\n",
    "model = RandomForestClassifier(max_depth=8, random_state=5)\n",
    "val_score, cv_score = ut.get_baseline_score(model, X_train, X_val, y_train, y_val)\n",
    "\n",
    "# get baseline score - lgbm\n",
    "model = LGBMClassifier(random_state=5)\n",
    "val_score, cv_score = ut.get_baseline_score(model, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correlation matrix\n",
    "df_temp = copy.deepcopy(df_train)\n",
    "for col in df_temp.columns:\n",
    "    if df_temp[col].dtypes == 'category':\n",
    "        df_temp[col] = df_temp[col].astype('uint8')\n",
    "\n",
    "target = df_temp['Cover_Type']\n",
    "features = df_temp.drop('Cover_Type', axis=1)\n",
    "df_temp = features.iloc[:, :27]\n",
    "df_temp = pd.concat([df_temp, target], axis=1)\n",
    "\n",
    "corrmat = df_temp.corr()\n",
    "top_corr_features = corrmat.index\n",
    "\n",
    "plt.figure(figsize=(40,40))\n",
    "g=sns.heatmap(df_temp[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score 0.903\n",
      "cross val score 0.905\n",
      "Wall time: 44min 41s\n"
     ]
    }
   ],
   "source": [
    "# get feature importances\n",
    "featureScores = ut.get_feature_importances(X_train, y_train, 5)\n",
    "featureScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score 0.952\n",
      "cross val score 0.952\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get drop scores\n",
    "model = LGBMClassifier(random_state=5)\n",
    "df_drops = ut.get_drop_scores(model, X_train, X_val, y_train, y_val, False)\n",
    "val_cols = list(df_drops.sort_values(by='val_score', ascending=False).head(15)['col'])\n",
    "cv_cols = list(df_drops.sort_values(by='cv_score', ascending=False).head(15)['col'])\n",
    "common_cols = [c for c in val_cols if c in cv_cols]\n",
    "common_cols\n",
    "\n",
    "X_train_new = copy.deepcopy(X_train)\n",
    "X_val_new = copy.deepcopy(X_val)\n",
    "X_train_new.drop(common_cols, axis=1, inplace=True)\n",
    "X_val_new.drop(common_cols, axis=1, inplace=True)\n",
    "\n",
    "val_score, cv_score = ut.get_baseline_score(model, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get kmeans scores\n",
    "ut.get_kmeans_scores(featureScores, X_train, X_val, df_test, models)\n",
    "\n",
    "# get kmeans scores on validation set\n",
    "ut.get_kmeans_scores_validation(featureScores, X_train, X_val, df_test, models)\n",
    "\n",
    "# get stacking scores\n",
    "stack_model = LogisticRegression(solver='sag', C=1.6213309780417264, max_iter=1800, random_state=10)\n",
    "ut.get_stacking_scores(featureScores, X_train, y_train, X_val, df_test, models, stack_model)\n",
    "\n",
    "# get binning scores\n",
    "baseline_score = 0.749\n",
    "model = LinearSVC(dual=False, C=0.012249147757314706, max_iter=10000)\n",
    "improved_cols = ut.get_binning_scores(baseline_score, X_train, y_train, model, 0.01)\n",
    "\n",
    "# get binning scores on validation set\n",
    "baseline_score = 0.749\n",
    "improvement = 0.5\n",
    "model = LinearSVC(dual=False, C=0.012249147757314706, max_iter=10000)\n",
    "improved_cols = ut.get_binning_scores_val(baseline_score, X_train, y_train, X_val, y_val, model, improvement)\n",
    "\n",
    "# optimize model\n",
    "ut.optimize_linear_svc(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# final prediction - single model - logistic regression\n",
    "clf = LogisticRegression(solver='newton-cg', C=0.023672809391721117, max_iter=200)\n",
    "ut.make_final_pred_single(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(df_test)\n",
    "\n",
    "output = pd.DataFrame({'Id': ids, 'Cover_Type': preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
